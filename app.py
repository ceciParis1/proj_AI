import streamlit as st
import os
import dotenv
import uuid
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage
from rag_methods import (
    get_poems_from_poetrydb,
    stream_llm_response,
    stream_llm_rag_response,
)

dotenv.load_dotenv()

# Configuration de la page avec des √©l√©ments visuels
st.set_page_config(
    page_title="Recherche et Analyse de Po√®mes avec LLM", 
    page_icon="üìö", 
    layout="centered", 
    initial_sidebar_state="expanded"
)

# Titre principal avec style
st.markdown("<h1 style='text-align: center; color: #4CAF50;'>Recherche et Analyse de Po√®mes avec LLM</h1>", unsafe_allow_html=True)
st.markdown("<hr>", unsafe_allow_html=True)

# Ajout de texte d'introduction
st.markdown("""
<div style='text-align: center;'>
    <p>Utilisez cette application pour trouver des po√®mes selon un th√®me et les analyser gr√¢ce √† un mod√®le de langage.</p>
    <p style='color: #6c757d;'>Propuls√© par GPT-4 et PoetryDB</p>
</div>
""", unsafe_allow_html=True)

# Ins√©rer directement la cl√© API ici (c'est temporaire et non recommand√© pour la production)
api_key = "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"

# V√©rifier si la cl√© est bien pr√©sente
if not api_key:
    st.error("Cl√© API OpenAI manquante. Assurez-vous de l'ins√©rer correctement dans le fichier app.py.")
else:
    st.success("Cl√© API OpenAI charg√©e avec succ√®s.")

# Initialiser le mod√®le OpenAI
llm_stream = ChatOpenAI(
    api_key=api_key,  # Utiliser la cl√© API ici
    model_name="gpt-4",
    temperature=0.7,
    streaming=True,
)

# Initialisation de la session
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Bienvenue ! Je peux vous aider √† trouver des po√®mes et √† en discuter ou les analyser."}
    ]

# Affichage des messages de la session avec mise en forme
for message in st.session_state.messages:
    role = "Utilisateur" if message["role"] == "user" else "Assistant"
    color = "#3498db" if message["role"] == "user" else "#2ecc71"
    st.markdown(f"<div style='background-color:{color};padding:10px;border-radius:10px;color:white;'><strong>{role}:</strong><br>{message['content']}</div>", unsafe_allow_html=True)
    st.markdown("<br>", unsafe_allow_html=True)

# Saisie d'un nouveau message par l'utilisateur
if prompt := st.chat_input("Votre message"):
    # V√©rification si le message contient un th√®me pour la recherche de po√®mes
    if "th√®me" in prompt.lower():
        # Extraire le th√®me du message
        theme = prompt.split("th√®me")[-1].strip()
        linecount = st.number_input("Longueur des vers (en nombre de lignes, optionnel)", min_value=1, step=1)
        st.session_state.messages.append({"role": "user", "content": f"Recherche de po√®mes sur le th√®me '{theme}' avec {linecount} vers."})

        # Recherche de po√®mes via PoetryDB
        poems = get_poems_from_poetrydb(theme=theme, linecount=linecount)

        if poems:
            for poem in poems:
                with st.chat_message("assistant"):
                    st.markdown(f"**{poem['title']}**\n\n" + "\n".join(poem['lines']))
                    st.session_state.messages.append({"role": "assistant", "content": f"**{poem['title']}**\n\n" + "\n".join(poem['lines'])})

            # Utilisation du LLM pour fournir une analyse litt√©raire
            with st.chat_message("assistant"):
                user_prompt = f"Voici un po√®me sur {theme} avec {linecount} vers. Peux-tu en faire une analyse litt√©raire ?"
                messages = [HumanMessage(content=user_prompt)]

                full_response = ""
                placeholder = st.empty()  # Cr√©er un espace r√©serv√© pour accumuler et afficher les r√©sultats

                for chunk in llm_stream.stream(messages):
                    full_response += chunk.content  # Ajout du texte sans espaces suppl√©mentaires
                    # Ajout d'une mise en forme du po√®me avec deux sauts de ligne pour s√©parer les strophes
                    formatted_text = full_response.replace('\n', '  \n')  
                    placeholder.markdown(formatted_text)  # Affichage du texte accumul√© progressivement avec la bonne mise en forme

                st.session_state.messages.append({"role": "assistant", "content": full_response})
        else:
            st.warning("Aucun po√®me trouv√© avec les crit√®res sp√©cifi√©s.")
            st.session_state.messages.append({"role": "assistant", "content": "Aucun po√®me trouv√© avec les crit√®res sp√©cifi√©s."})
    else:
        # Enregistrement du message utilisateur
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("user"):
            st.markdown(prompt)

        # R√©ponse du LLM
        with st.chat_message("assistant"):
            # V√©rification que le prompt n'est pas vide
            if prompt:
                messages = [HumanMessage(content=prompt)]
                full_response = ""
                placeholder = st.empty()  # Espace r√©serv√© pour la r√©ponse

                # It√©ration sur le g√©n√©rateur pour afficher la r√©ponse du LLM
                for chunk in stream_llm_response(llm_stream, messages):
                    full_response += chunk  # Ajout du chunk sans espace suppl√©mentaire
                    # Ajout de la mise en forme avec des retours √† la ligne appropri√©s
                    formatted_text = full_response.replace('\n', '  \n')
                    placeholder.markdown(formatted_text)  # Affichage du chunk dans l'interface

                # Enregistrement de la r√©ponse compl√®te dans l'√©tat de session
                st.session_state.messages.append({"role": "assistant", "content": full_response})
            else:
                st.warning("Veuillez saisir un message avant de soumettre.")
