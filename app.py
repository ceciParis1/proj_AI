import streamlit as st
import os
import dotenv
import uuid
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage
from rag_methods import (
    get_poems_from_poetrydb,
    stream_llm_response,
    stream_llm_rag_response,
)

dotenv.load_dotenv()

# Configuration de la page avec des √©l√©ments visuels
st.set_page_config(
    page_title="Recherche et Analyse de Po√®mes avec LLM", 
    page_icon="üìö", 
    layout="centered", 
    initial_sidebar_state="expanded"
)

# Titre principal avec style
st.markdown("<h1 style='text-align: center; color: #4CAF50;'>Recherche et Analyse de Po√®mes avec LLM</h1>", unsafe_allow_html=True)
st.markdown("<hr>", unsafe_allow_html=True)

# Ajout de texte d'introduction
st.markdown("""
<div style='text-align: center;'>
    <p>Utilisez cette application pour trouver des po√®mes selon un th√®me et les analyser gr√¢ce √† un mod√®le de langage.</p>
    <p style='color: #6c757d;'>Propuls√© par GPT-4 et PoetryDB</p>
</div>
""", unsafe_allow_html=True)

# Ins√©rer directement la cl√© API ici (c'est temporaire et non recommand√© pour la production)
api_key = "\documentclass{beamer}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{hyperref}
\usepackage{xcolor}

% Th√®me et couleurs
\usetheme{Madrid} % Th√®me Beamer Madrid
\usecolortheme{seagull} % Sch√©ma de couleurs neutres

% Couleurs personnalis√©es
\definecolor{myblue}{RGB}{0,102,204}
\setbeamercolor{structure}{fg=myblue}
\setbeamercolor{frametitle}{fg=myblue}
\setbeamercolor{title}{fg=myblue}

% Supprimer le pied de page avec le titre
\setbeamertemplate{footline}{}

% Titre de la pr√©sentation
\title{Recherche et analyse de po√®mes avec LLM}
\subtitle{Une solution IA pour l'analyse litt√©raire automatis√©e}
\author{RUSSO C√©cilia & DUPUIS Marine}
\institute{Paris 1 - Panth√©on Sorbonne}
\date{Octobre 2024}

\begin{document}

% Diapositive de titre
\begin{frame}
    \titlepage
\end{frame}

% Table des mati√®res
\begin{frame}{Sommaire}
    \tableofcontents
\end{frame}

% Section Introduction
\section{Introduction}

\begin{frame}{Contexte et Objectifs}
    \textbf{Contexte :} L'intelligence artificielle permet d√©sormais de transformer la mani√®re d'analyser les textes litt√©raires.
    
    \vspace{0.5cm}
    
    \textbf{Objectif :} Utiliser \textbf{GPT-4} et \textbf{PoetryDB} pour offrir une application permettant la recherche et l'analyse automatis√©e de po√®mes.
    
    \vspace{0.5cm}
    
    \textbf{Lien vers l'application :} \href{https://projai-dwqgjwsgzzvgk2dbx39dyn.streamlit.app/}{Application Streamlit}
\end{frame}

% Section Fonctionnalit√©s Cl√©s
\section{Fonctionnalit√©s}

\begin{frame}{Fonctionnalit√©s de l'Application}
    \begin{itemize}
        \item Recherche de po√®mes via \textbf{PoetryDB} en fonction du th√®me ou du nombre de lignes.
        \item Analyse litt√©raire automatis√©e avec \textbf{GPT-4}.
        \item Interface utilisateur simple et fluide avec \textbf{Streamlit}.
    \end{itemize}
    
    \vspace{0.5cm}
    
    \textbf{Avantage :} Adaptation pour des utilisateurs acad√©miques ou professionnels (√©ducation, √©dition).
\end{frame}

% Section Interface Utilisateur avec Images
\section{Interface Utilisateur}

\begin{frame}{Interface Utilisateur - Capture 1}
    Voici une capture d'√©cran de l'application montrant l'interface principale :
    \begin{figure}[ht]
        \centering
        \includegraphics[width=0.8\textwidth]{/mnt/data/Image1.png}
        \caption{Interface principale de l'application}
    \end{figure}
\end{frame}

\begin{frame}{Interface Utilisateur - Capture 2}
    Exemple d'une recherche de po√®mes avec un th√®me sp√©cifique :
    \begin{figure}[ht]
        \centering
        \includegraphics[width=0.8\textwidth]{/mnt/data/Image2.png}
        \caption{Recherche de po√®mes sur le th√®me des fleurs}
    \end{figure}
\end{frame}

\begin{frame}{Interface Utilisateur - Analyse Litt√©raire}
    Fonctionnalit√©s de g√©n√©ration et d'analyse de po√®mes par l'IA :
    \begin{figure}[ht]
        \centering
        \includegraphics[width=0.8\textwidth]{/mnt/data/Image3.png}
        \caption{Liste des capacit√©s de l'IA en analyse de po√®mes}
    \end{figure}
\end{frame}

\begin{frame}{G√©n√©ration de Po√®mes}
    Voici un exemple de g√©n√©ration de po√®mes par l'application :
    \begin{figure}[ht]
        \centering
        \includegraphics[width=0.8\textwidth]{/mnt/data/Image4.png}
        \caption{Po√®me g√©n√©r√© inspir√© par Alfred de Musset}
    \end{figure}
\end{frame}

\begin{frame}{Exemple de Po√®mes C√©l√®bres}
    La capacit√© de retrouver des po√®mes c√©l√®bres comme celui de Victor Hugo :
    \begin{figure}[ht]
        \centering
        \includegraphics[width=0.8\textwidth]{/mnt/data/Image5.png}
        \caption{Po√®me c√©l√®bre de Victor Hugo : Demain, d√®s l'aube}
    \end{figure}
\end{frame}

\begin{frame}{Biographies de Po√®tes}
    Exemple de la fonctionnalit√© pour obtenir des biographies :
    \begin{figure}[ht]
        \centering
        \includegraphics[width=0.8\textwidth]{/mnt/data/Image6.png}
        \caption{Biographie de Charles Baudelaire}
    \end{figure}
\end{frame}

% Section M√©thodologie Technique
\section{M√©thodologie Technique}

\begin{frame}{Architecture et Technologies Utilis√©es}
    \textbf{Technologies :}
    \begin{itemize}
        \item \textbf{GPT-4} : G√©n√©ration d'analyses textuelles.
        \item \textbf{PoetryDB} : Base de donn√©es pour la recherche de po√®mes.
        \item \textbf{Streamlit} : Interface web simple pour l'utilisateur.
        \item \textbf{Langchain} : Gestion des appels au mod√®le GPT-4.
    \end{itemize}
    
    \vspace{0.5cm}
    
    \textbf{Flux de Travail :} Saisie de th√®me ‚Üí Recherche de po√®mes ‚Üí Analyse via GPT-4 ‚Üí Affichage des r√©sultats.
\end{frame}

% Section Avantages Commerciaux
\section{Opportunit√©s Commerciales}

\begin{frame}{Potentiel Commercial}
    \begin{itemize}
        \item \textbf{Secteur √©ducatif :} Outil d'analyse pour les √©coles et universit√©s.
        \item \textbf{√âditeurs :} Analyses automatis√©es pour les maisons d'√©dition.
        \item \textbf{Exp√©rience utilisateur :} Interaction intuitive pour les amateurs de po√©sie et les chercheurs litt√©raires.
    \end{itemize}
    
    \vspace{0.5cm}
    
    \textbf{Lien vers l'application :} \href{https://projai-dwqgjwsgzzvgk2dbx39dyn.streamlit.app/}{Application Streamlit}
\end{frame}

% Section Conclusion et Perspectives
\section{Conclusion et Perspectives}

\begin{frame}{Conclusion et Prochaines √âtapes}
    \textbf{Conclusion :}
    \begin{itemize}
        \item Application innovante combinant recherche po√©tique et analyse IA.
        \item D√©j√† applicable dans plusieurs secteurs (√©ducation, √©dition).
    \end{itemize}

    \vspace{0.5cm}
    
    \textbf{Perspectives :}
    \begin{itemize}
        \item Int√©gration de nouveaux types de textes (narratifs, essais).
        \item Expansion linguistique pour couvrir plusieurs langues.
    \end{itemize}
\end{frame}

\end{document}
"

# V√©rifier si la cl√© est bien pr√©sente
if not api_key:
    st.error("Cl√© API OpenAI manquante. Assurez-vous de l'ins√©rer correctement dans le fichier app.py.")
else:
    st.success("Cl√© API OpenAI charg√©e avec succ√®s.")

# Initialiser le mod√®le OpenAI
llm_stream = ChatOpenAI(
    api_key=api_key,  # Utiliser la cl√© API ici
    model_name="gpt-4",
    temperature=0.7,
    streaming=True,
)

# Initialisation de la session
if "session_id" not in st.session_state:
    st.session_state.session_id = str(uuid.uuid4())

if "messages" not in st.session_state:
    st.session_state.messages = [
        {"role": "assistant", "content": "Bienvenue ! Je peux vous aider √† trouver des po√®mes et √† en discuter ou les analyser."}
    ]

# Affichage des messages de la session avec mise en forme
for message in st.session_state.messages:
    role = "Utilisateur" if message["role"] == "user" else "Assistant"
    color = "#3498db" if message["role"] == "user" else "#2ecc71"
    st.markdown(f"<div style='background-color:{color};padding:10px;border-radius:10px;color:white;'><strong>{role}:</strong><br>{message['content']}</div>", unsafe_allow_html=True)
    st.markdown("<br>", unsafe_allow_html=True)

# Saisie d'un nouveau message par l'utilisateur
if prompt := st.chat_input("Votre message"):
    # V√©rification si le message contient un th√®me pour la recherche de po√®mes
    if "th√®me" in prompt.lower():
        # Extraire le th√®me du message
        theme = prompt.split("th√®me")[-1].strip()
        linecount = st.number_input("Longueur des vers (en nombre de lignes, optionnel)", min_value=1, step=1)
        st.session_state.messages.append({"role": "user", "content": f"Recherche de po√®mes sur le th√®me '{theme}' avec {linecount} vers."})

        # Recherche de po√®mes via PoetryDB
        poems = get_poems_from_poetrydb(theme=theme, linecount=linecount)

        if poems:
            for poem in poems:
                with st.chat_message("assistant"):
                    st.markdown(f"**{poem['title']}**\n\n" + "\n".join(poem['lines']))
                    st.session_state.messages.append({"role": "assistant", "content": f"**{poem['title']}**\n\n" + "\n".join(poem['lines'])})

            # Utilisation du LLM pour fournir une analyse litt√©raire
            with st.chat_message("assistant"):
                user_prompt = f"Voici un po√®me sur {theme} avec {linecount} vers. Peux-tu en faire une analyse litt√©raire ?"
                messages = [HumanMessage(content=user_prompt)]

                full_response = ""
                placeholder = st.empty()  # Cr√©er un espace r√©serv√© pour accumuler et afficher les r√©sultats

                for chunk in llm_stream.stream(messages):
                    full_response += chunk.content  # Ajout du texte sans espaces suppl√©mentaires
                    # Ajout d'une mise en forme du po√®me avec deux sauts de ligne pour s√©parer les strophes
                    formatted_text = full_response.replace('\n', '  \n')  
                    placeholder.markdown(formatted_text)  # Affichage du texte accumul√© progressivement avec la bonne mise en forme

                st.session_state.messages.append({"role": "assistant", "content": full_response})
        else:
            st.warning("Aucun po√®me trouv√© avec les crit√®res sp√©cifi√©s.")
            st.session_state.messages.append({"role": "assistant", "content": "Aucun po√®me trouv√© avec les crit√®res sp√©cifi√©s."})
    else:
        # Enregistrement du message utilisateur
        st.session_state.messages.append({"role": "user", "content": prompt})

        with st.chat_message("user"):
            st.markdown(prompt)

        # R√©ponse du LLM
        with st.chat_message("assistant"):
            # V√©rification que le prompt n'est pas vide
            if prompt:
                messages = [HumanMessage(content=prompt)]
                full_response = ""
                placeholder = st.empty()  # Espace r√©serv√© pour la r√©ponse

                # It√©ration sur le g√©n√©rateur pour afficher la r√©ponse du LLM
                for chunk in stream_llm_response(llm_stream, messages):
                    full_response += chunk  # Ajout du chunk sans espace suppl√©mentaire
                    # Ajout de la mise en forme avec des retours √† la ligne appropri√©s
                    formatted_text = full_response.replace('\n', '  \n')
                    placeholder.markdown(formatted_text)  # Affichage du chunk dans l'interface

                # Enregistrement de la r√©ponse compl√®te dans l'√©tat de session
                st.session_state.messages.append({"role": "assistant", "content": full_response})
            else:
                st.warning("Veuillez saisir un message avant de soumettre.")
